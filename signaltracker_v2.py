# -*- coding: utf-8 -*-
"""SignalTracker_V2_InputAndScoring_Prototype.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Vc0YieCO-lWDuA4FL6cWRIVOt321kFMO

# üõ†Ô∏è Environment Setup & NLP
"""

# === Install and set up spaCy ===

import spacy
nlp = spacy.load("en_core_web_sm")

# === Region extraction function ===
def extract_region_from_text(text):
    doc = nlp(text)
    for ent in doc.ents:
        if ent.label_ == "GPE":
            return ent.text
    return "Unknown"

"""# üìå üåé Region Extraction & Normalization"""

# === REGION NORMALIZATION FUNCTION ===
BROAD_REGION_MAP = {
    "Asia-Pacific": ["China", "Japan", "South Korea", "Australia", "India"],
    "Middle East": ["Saudi Arabia", "Iran", "Israel", "UAE", "Turkey"],
    "Europe": ["Germany", "France", "UK", "Italy", "Spain"],
    "Africa": [],  # too broad ‚Üí Unknown
    "South America": ["Brazil", "Argentina", "Chile", "Colombia"],
    "North America": ["United States", "Canada", "Mexico"],
    # Extend as needed...
}

def normalize_region(region_text):
    """
    Normalize broad regions ‚Üí list of countries or Unknown,
    and assign region_confidence and precision_flag.
    """
    region_text = region_text.strip()
    if region_text in BROAD_REGION_MAP:
        countries = BROAD_REGION_MAP[region_text]
        if countries:
            return countries, 0.5, False  # mapped list, lower confidence
        else:
            return ["Unknown"], 0.3, False
    else:
        return [region_text], 1.0, True

"""# üìä Scoring Lookup Tables


1.   List item
2.   List item


"""

# === LOOKUP TABLES ===
credibility_scores = {
"Bloomberg": 10,
"Reuters": 8,
"Telegram": 5,
"Darknet": 2
}

urgency_scores = {
"CDS_SOV_SPIKE": 8,
"PROTEST_CLUSTERING": 9,
"NDVI_ANOMALY": 5
}

sensitivity_scores = {
"CDS_SOV_SPIKE": 9,
"PROTEST_CLUSTERING": 6,
"NDVI_ANOMALY": 7
}

"""# üîó Google Sheets Connection & Deduplication

"""

import pandas as pd
from datetime import datetime, timedelta
import os

excel_path = "signals.xlsx"

# Load existing data if it exists
if os.path.exists(excel_path):
    existing_df = pd.read_excel(excel_path, sheet_name="Primary", engine="openpyxl")
else:
    existing_df = pd.DataFrame()

if not existing_df.empty and "timestamp" in existing_df.columns:
    existing_df["timestamp"] = pd.to_datetime(existing_df["timestamp"], errors="coerce")

"""# üß™ Test Signals Setup & Processing

"""

# === SCORING FUNCTION ===

def calculate_signal_score(signal):
    matcher = signal["matcher_name"]
    source = signal["source"]

    credibility_score = credibility_scores.get(source, 5)
    urgency_score = urgency_scores.get(matcher, 5)
    sensitivity_score = sensitivity_scores.get(matcher, 5)

    # Original base final score
    base_final_score = round(
        (credibility_score * 0.4) +
        (urgency_score * 0.3) +
        (sensitivity_score * 0.3), 2
    )

    # === DYNAMIC CONFIDENCE PENALTIES ===
    penalty = 0
    penalty_reasons = []

    # 1Ô∏è‚É£ Low region confidence
    region_confidence = signal.get("region_confidence", 1.0)
    if region_confidence < 0.5:
        penalty += 2  # adjust weight as needed
        penalty_reasons.append("Low region confidence")

    # 2Ô∏è‚É£ Weak classification
    classified_event = signal.get("classified_event", "").lower()
    if classified_event in ["", "other/miscellaneous"]:
        penalty += 1
        penalty_reasons.append("Weak classification")

    # Apply penalty
    final_score = max(0, round(base_final_score - penalty, 2))

    # Determine confidence flag
    if final_score >= 8:
        confidence_flag = "High"
    elif final_score >= 5:
        confidence_flag = "Medium"
    else:
        confidence_flag = "Low"

    # Update signal dictionary
    signal["credibility_score"] = credibility_score
    signal["urgency_score"] = urgency_score
    signal["historical_sensitivity_score"] = sensitivity_score
    signal["base_final_score"] = base_final_score
    signal["score_penalty"] = penalty
    signal["penalty_reason"] = "; ".join(penalty_reasons) if penalty_reasons else "None"
    signal["final_score"] = final_score
    signal["confidence_flag"] = confidence_flag
    signal["forward_to_classifier"] = (confidence_flag == "High")
    signal["schema_version"] = "v1.1"  # updated version for recalibration
    signal["last_updated"] = datetime.utcnow().isoformat()

    return signal

"""#  ‚öôÔ∏è Signal Scoring & Processing Loop

"""

from datetime import datetime

test_signals = [
    {
        "matcher_name": "CDS_CDV_SPIKE",
        "source": "Bloomberg",
        "raw_value": "144",
        "indicator_type": "Sovereign CDS",
        "category": "Economic",
        "region": "Asia-Pacific",
        "timestamp": "2025-06-25T12:42:00Z"
    },
    {
        "matcher_name": "PROTEST_CLUSTERING",
        "source": "Reuters",
        "raw_value": "4 cities in 48h",
        "indicator_type": "Civil Unrest",
        "category": "Geopolitical",
        "region": "South America",
        "timestamp": "2025-06-25T13:05:00Z"
    },
    {
        "matcher_name": "MISSILE_WATCH",
        "source": "Al Jazeera",
        "raw_value": "BREAKING: Major missile attack strikes capital city",
        "indicator_type": "News Headline",
        "category": "Geopolitical",
        "region": "Iran",
        "timestamp": "2025-07-07T18:00:00Z"
    }
]

scored_signals = []

for signal in test_signals:
    # === Normalize region first ===
    normalized_region, region_confidence, precision_flag = normalize_region(signal['region'])
    signal["region"] = ', '.join(normalized_region)
    signal["region_confidence"] = region_confidence
    signal["region_precision_flag"] = precision_flag

    # === Deduplication check ===
    is_duplicate = False

    if not existing_df.empty:
        # Filter existing signals with matching classified_event + region
        recent_matches = existing_df[
            (existing_df["classified_event"] == signal.get("classified_event", "")) &
            (existing_df["region"] == signal.get("region", ""))
        ]

        # Check timestamps within ¬±10 minutes (600 seconds)
        for _, existing_row in recent_matches.iterrows():
            existing_time = existing_row["timestamp"]
            new_time = pd.to_datetime(signal["timestamp"], errors="coerce")
            if abs((new_time - existing_time).total_seconds()) <= 600:
                is_duplicate = True
                break

    if not is_duplicate:
        signal["heartbeat"] = datetime.utcnow().isoformat()
        scored = calculate_signal_score(signal)
        scored_signals.append(scored)
    else:
        print(f"[üîÅDEDUPLICATION] Skipped duplicate: {signal.get('classified_event', 'Unknown')} | {signal.get('region', 'Unknown')} at {signal.get('timestamp', 'Unknown')}")

# üêõ Optional: Print the last 3 scored signals for debug
for sig in scored_signals[-3:]:
    print(sig)

"""# ü´Ä System Logging & Heartbeat"""

log = []

for signal in test_signals:
    try:
        scored = calculate_signal_score(signal)
        log.append({
            "timestamp": datetime.utcnow().isoformat(),
            "matcher": scored["matcher_name"],
            "status": "Success",
            "final_score": scored["final_score"]
        })
    except Exception as e:
        log.append({
            "timestamp": datetime.utcnow().isoformat(),
            "matcher": signal.get("matcher_name", "UNKNOWN"),
            "status": f"Fail - {str(e)}"
        })

# View the log (optional)
pd.DataFrame(log)

import requests
import pandas as pd
from datetime import datetime

# === CONFIG ===
newsapi_key = "c18ba3121e474c7d837c5415f7fc25e7"  # Replace with your real key

# Expanded keywords to match your indicators
keywords = (
    "protest OR strike OR coup OR riot OR military OR "
    "earthquake OR tsunami OR volcano OR hurricane OR "
    "wildfire OR drought OR flood OR ransomware OR cyberattack OR "
    "data breach OR missile OR invasion OR default OR "
    "currency collapse OR supply chain OR port strike OR logistics crisis"
)

newsapi_url = (
    f"https://newsapi.org/v2/everything?q={keywords}"
    f"&language=en&sortBy=publishedAt&pageSize=20&apiKey={newsapi_key}"
)

# === FETCH NEWS ===
response = requests.get(newsapi_url)
if response.status_code != 200:
    raise Exception(f"Failed to fetch NewsAPI: {response.status_code}, {response.text}")

articles = response.json().get("articles", [])
print(f"[INFO] Retrieved {len(articles)} articles.")

# === CONVERT TO SIGNALS WITH REGION EXTRACTION ===
news_signals = []

for article in articles:
    headline = article.get("title", "N/A")
    extracted_region = extract_region_from_text(headline)

    # === Normalize the extracted region ===
    normalized_region, region_confidence, precision_flag = normalize_region(extracted_region)

    # Build signal dict with normalized region info
    signal = {
        "matcher_name": "NEWS_KEYWORD_MATCH",
        "source": "NewsAPI",
        "raw_value": headline,
        "indicator_type": "News Headline",
        "category": "Geopolitical/Economic/Natural",
        "region": ', '.join(normalized_region),
        "timestamp": article.get("publishedAt", datetime.utcnow().isoformat()),
        "region_confidence": region_confidence,
        "region_precision_flag": precision_flag
    }

    # === Deduplication check using raw_value and region ===
    is_duplicate = False

    if not existing_df.empty:
        recent_matches = existing_df[
            (existing_df["raw_value"] == signal.get("raw_value", "")) &
            (existing_df["region"] == signal.get("region", ""))
        ]

        for _, existing_row in recent_matches.iterrows():
            existing_time = existing_row["timestamp"]
            new_time = pd.to_datetime(signal["timestamp"], errors="coerce")
            if abs((new_time - existing_time).total_seconds()) <= 600:
                is_duplicate = True
                break

    if not is_duplicate:
        # Add heartbeat timestamp
        signal["heartbeat"] = datetime.utcnow().isoformat()
        scored_signal = calculate_signal_score(signal)
        news_signals.append(scored_signal)
    else:
        print(f"[üîÅDEDUPLICATION] Skipped duplicate: {signal.get('raw_value', 'UNKNOWN')} | {signal['region']} at {signal['timestamp']}")

"""# üè∑Ô∏è Event Classification & Export"""

# === EVENT CLASSIFIER ===

def classify_event(signal):
    text = signal["raw_value"].lower()
    matcher = signal.get("matcher_name", "").upper()

    # Keyword-based classification
    if any(keyword in text for keyword in ["protest", "demonstration", "rally"]):
        label = "Protest"
    elif any(keyword in text for keyword in ["strike", "walkout", "labor action"]):
        label = "Strike"
    elif any(keyword in text for keyword in ["coup", "overthrow", "regime change"]):
        label = "Coup/Political Unrest"
    elif any(keyword in text for keyword in ["missile", "attack", "invasion", "airstrike"]):
        label = "Military Escalation"
    elif any(keyword in text for keyword in ["earthquake", "tsunami", "volcano", "hurricane", "wildfire", "flood", "drought"]):
        label = "Natural Disaster"
    elif any(keyword in text for keyword in ["ransomware", "cyberattack", "data breach"]):
        label = "Cyberattack"
    elif any(keyword in text for keyword in ["default", "cds", "credit default", "spread widening", "currency collapse", "financial crisis"]):
        label = "Economic Crisis"
    elif any(keyword in text for keyword in ["port strike", "shipping delay", "logistics crisis"]):
        label = "Supply Chain Disruption"
    else:
        # NEW matcher_name fallback
        if "PROTEST_CLUSTERING" in matcher:
            label = "Protest"
        elif signal["category"].lower().startswith("economic"):
            label = "Economic Crisis"
        else:
            label = "Other/Miscellaneous"

    signal["classified_event"] = label
    return signal

# === APPLY CLASSIFIER ===
classified_signals = []
for signal in scored_signals + news_signals:
    classified = classify_event(signal)

    # === MAJOR EVENT TRIGGER ALERT ===
    try:
        if classified.get("final_score", 0) >= 9 and classified.get("region_confidence", 0) >= 0.8:
            print("üö® MAJOR SIGNAL DETECTED")
            print(f"> Type: {classified.get('classified_event')}")
            print(f"> Region: {classified.get('region')} | Score: {classified.get('final_score')}")
            print(f"> Signal: {classified.get('raw_value')}")
    except Exception as e:
        print(f"[Alert Trigger Error] {e}")

    # === Forwarding Flag Logic ===
    if classified.get("confidence_flag") == "High" and classified.get("region") != "Unknown":
        classified["forward_to_engine"] = True
    else:
        classified["forward_to_engine"] = False

    classified_signals.append(classified)

# === ARCHIVE TO 'AllSignalsArchive' SHEET ===

try:
    archive_df = pd.DataFrame(classified_signals)

    with pd.ExcelWriter(excel_path, engine="openpyxl", mode="a" if os.path.exists(excel_path) else "w", if_sheet_exists="replace") as writer:
        archive_df.to_excel(writer, sheet_name="AllSignalsArchive", index=False)

    print("üì¶ Full signal archive saved to Excel.")
except Exception as e:
    print(f"‚ö†Ô∏è Archive error: {e}")



# === EXPORT TO PRIMARY SHEET ===
df_classified = pd.DataFrame(classified_signals)

with pd.ExcelWriter(excel_path, engine="openpyxl", mode="a" if os.path.exists(excel_path) else "w", if_sheet_exists="replace") as writer:

    df_classified.to_excel(writer, sheet_name="Primary", index=False)

print("[INFO] Signals classified and saved to Excel (Primary sheet).")


# === FORWARD TO INDUSTRY ENGINE SHEET IF FLAGGED ===
try:
    forwarded_signals = [s for s in classified_signals if s.get("forward_to_engine")]

    if forwarded_signals:
        forward_df = pd.DataFrame(forwarded_signals)

        with pd.ExcelWriter(excel_path, engine="openpyxl", mode="a" if os.path.exists(excel_path) else "w", if_sheet_exists="replace") as writer:
            forward_df.to_excel(writer, sheet_name="IndustryEngineInput", index=False)


        print(f"‚úÖ Forwarded {len(forward_df)} signals to IndustryEngineInput.")
    else:
        print("‚ÑπÔ∏è No signals to forward.")
except Exception as e:
    print(f"‚ö†Ô∏è Forwarding error: {e}")

"""#  üìä New Cell: Post-Processing Diagnostic Summary"""