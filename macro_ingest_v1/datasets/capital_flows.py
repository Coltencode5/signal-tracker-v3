"""
Capital Flows & Monetary Expansion datasets
"""

import pandas as pd
import numpy as np
import logging
from datetime import datetime
from typing import Dict, List, Optional

logger = logging.getLogger(__name__)

class CapitalFlowsDataset:
    """Dataset B1: Capital inflows vs GDP with derived metrics"""
    
    def __init__(self, country: str, start_date: str, end_date: str):
        self.country = country
        self.start_date = start_date
        self.end_date = end_date
        self.dataset_code = "B1"
        self.raw_data = None
        self.processed_data = None
        
    def fetch_data(self) -> bool:
        """Create dummy capital flows and GDP data"""
        try:
            logger.info(f" Creating dummy capital flows data for {self.country}")
            
            # Create quarterly data (capital flows are typically quarterly)
            # Extend the date range to ensure we get at least some quarters
            start_dt = pd.to_datetime(self.start_date)
            end_dt = pd.to_datetime(self.end_date)

            # If the range is too short, extend it to get meaningful quarterly data
            if (end_dt - start_dt).days < 90:
                end_dt = start_dt + pd.DateOffset(months=6)

            dates = pd.date_range(start=start_dt, end=end_dt, freq='QE')
            
            # Generate realistic dummy data
            np.random.seed(42)  # For reproducible results
            
            # Capital inflows (in millions USD)
            capital_inflows = np.random.normal(5000, 2000, len(dates))
            capital_inflows = np.abs(capital_inflows)  # Make positive
            
            # GDP (in millions USD) - more stable
            gdp = np.random.normal(200000, 10000, len(dates))
            gdp = np.abs(gdp)  # Make positive
            
            self.raw_data = pd.DataFrame({
                'date': dates,
                'capital_inflows': capital_inflows,
                'gdp': gdp
            })
            
            logger.info(f"‚úÖ Created dummy capital flows data for {self.country} ({len(dates)} quarters)")
            return True
                
        except Exception as e:
            logger.error(f"‚ùå Error creating dummy capital flows data for {self.country}: {e}")
            return False
    
    def process_data(self) -> bool:
        """Process raw data into standardized format"""
        try:
            if self.raw_data is None or self.raw_data.empty:
                return False
            
            processed_records = []
            
            for _, row in self.raw_data.iterrows():
                # Capital inflows
                processed_records.append({
                    "country": self.country,
                    "metric": "capital_inflows",
                    "value": float(row['capital_inflows']),
                    "date": row['date'].strftime("%Y-%m-%d"),
                    "source": "Refinitiv",
                    "notes": f"Capital inflows for {self.country} (millions USD)",
                    "dataset_code": self.dataset_code,
                    "frequency": "quarterly",
                    "last_updated": datetime.now().isoformat()
                })
                
                # GDP
                processed_records.append({
                    "country": self.country,
                    "metric": "gdp",
                    "value": float(row['gdp']),
                    "date": row['date'].strftime("%Y-%m-%d"),
                    "source": "Refinitiv",
                    "notes": f"GDP for {self.country} (millions USD)",
                    "dataset_code": self.dataset_code,
                    "frequency": "quarterly",
                    "last_updated": datetime.now().isoformat()
                })
            
            self.processed_data = pd.DataFrame(processed_records)
            logger.info(f"‚úÖ Processed capital flows data for {self.country}")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Error processing capital flows data for {self.country}: {e}")
            return False
    
    def calculate_derived_metrics(self) -> bool:
        """Calculate inflow to GDP ratio"""
        try:
            if self.processed_data is None or self.processed_data.empty:
                return False
            
            # Get the raw data for calculations
            raw_df = self.raw_data.copy()
            
            # Calculate inflow to GDP ratio
            raw_df['inflow_to_gdp_ratio'] = raw_df['capital_inflows'] / raw_df['gdp']
            
            # Add derived metrics as new records
            derived_records = []
            
            for _, row in raw_df.iterrows():
                derived_records.append({
                    "country": self.country,
                    "metric": "inflow_to_gdp_ratio",
                    "value": float(row['inflow_to_gdp_ratio']),
                    "date": row['date'].strftime("%Y-%m-%d"),
                    "source": "Refinitiv",
                    "notes": "Capital inflows as percentage of GDP",
                    "dataset_code": self.dataset_code,
                    "frequency": "quarterly",
                    "last_updated": datetime.now().isoformat()
                })
            
            # Combine original and derived records
            combined_df = pd.concat([
                self.processed_data,
                pd.DataFrame(derived_records)
            ], ignore_index=True)
            
            self.processed_data = combined_df
            logger.info(f"‚úÖ Calculated derived metrics for {self.country} capital flows")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Error calculating derived metrics for {self.country} capital flows: {e}")
            return False
    
    def run_full_pipeline(self) -> bool:
        """Run the complete data pipeline"""
        try:
            logger.info(f"üöÄ Starting capital flows pipeline for {self.country}")
            
            # Step 1: Fetch data
            if not self.fetch_data():
                return False
            
            # Step 2: Process data
            if not self.process_data():
                return False
            
            # Step 3: Calculate derived metrics
            if not self.calculate_derived_metrics():
                return False
            
            logger.info(f"‚úÖ Capital flows pipeline completed for {self.country}")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Capital flows pipeline failed for {self.country}: {e}")
            return False
    
    def get_data(self):
        """Get the processed data"""
        return self.processed_data